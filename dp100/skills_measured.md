# Skills measured as of January 16, 2025
- Audience profile: As exam candidate, you should have:
    - SME in applying DS & ML to implement & run ML workloads on Azure
    - knowledge of optimizing language models for AI apps using Azure AI
- Source: [MS Learn](https://learn.microsoft.com/en-us/credentials/certifications/resources/study-guides/dp-100)

Role responsibilities:
- Design & create suitable work env for DS workloads
- Explore data
- Train ML models
- Implement pipelines
- Run jobs to prepare for production
- Manage, deploy, & monitor scalable ML solutions
- Use LLMs for building AI applications

As exam candidate, you should have know-how in DS using:
- Azure ML
- MLflow
- Azure AI
- AI Search
- AI Services

## Skills at a glance
- Design & prepare a ML solution (20–25%)
- Explore data, & run experiments (20–25%)
- Train & deploy models (25–30%)
- Optimize language models for AI applications (25–30%)

### Design & prepare a ML solution (20–25%)
- Design an ML solution
- Create & manage resources in an Azure ML workspace
- Create & manage assets in an Azure ML workspace

#### Design a ML solution
- Identify the structure & format for datasets
- Determine the compute specifications for ML workload
- Select the development approach to train a model

#### Create & manage resources in an Azure ML workspace
- Create & manage workspaces
- Create & manage datastores
- Create & manage compute targets
- Set up Git integration for source control

#### Create & manage assets in an Azure ML workspace
- Create & manage data assets
- Create & manage environments
- Share assets across workspaces by using registries

### Explore data, & run experiments (20–25%)
- Use AutoML to explore optimal models
- Use notebooks for custom model training
- Automate hyperparameter tuning

#### Use automated ML to explore optimal models
- Use AutoML for tabular data
- Use AutoML for computer vision
- Use AutoML for natural language processing
- Select & understand training options, including preprocessing & algorithms
- Evaluate an automated ML run, including responsible AI guidelines

#### Use notebooks for custom model training
- Use the terminal to configure a compute instance
- Access & wrangle data in notebooks
- Wrangle data interactively with attached Synapse Spark pools & serverless Spark compute
- Retrieve features from a feature store to train a model
- Track model training by using MLflow
- Evaluate a model, including responsible AI guidelines

#### Automate hyperparameter tuning
- Select a sampling method
- Define the search space
- Define the primary metric
- Define early termination options

### Train & deploy models (25–30%)
#### Run model training scripts
- Consume data in a job
- Configure compute for a job run
- Configure an environment for a job run
- Track model training with MLflow in a job run
- Define parameters for a job
- Run a script as a job
- Use logs to troubleshoot job run errors

#### Implement training pipelines
- Create custom components
- Create a pipeline
- Pass data between steps in a pipeline
- Run & schedule a pipeline
- Monitor & troubleshoot pipeline runs

#### Manage models
- Define the signature in the MLmodel file
- Package a feature retrieval specification with the model artifact
- Register an MLflow model
- Assess a model by using responsible AI principles

#### Deploy a model
- Configure settings for online deployment
- Deploy a model to an online endpoint
- Test an online deployed service
- Configure compute for a batch deployment
- Deploy a model to a batch endpoint
- Invoke the batch endpoint to start a batch scoring job

### Optimize language models for AI applications (25–30%)
#### Prepare for model optimization
- Select & deploy a language model from the model catalog
- Compare language models using benchmarks
- Test a deployed language model in the playground
- Select an optimization approach

#### Optimize through prompt engineering & Prompt flow
- Test prompts with manual evaluation
- Define & track prompt variants
- Create prompt templates
- Define chaining logic with the Prompt flow SDK
- Use tracing to evaluate your flow

#### Optimize through Retrieval Augmented Generation (RAG)
- Prepare data for RAG, including cleaning, chunking, & embedding
- Configure a vector store
- Configure an Azure AI Search-based index store
- Evaluate your RAG solution

#### Optimize through fine-tuning
- Prepare data for fine-tuning
- Select an appropriate base model
- Run a fine-tuning job
- Evaluate your fine-tuned model

